# Example of a simple MDP implementation in Python
import numpy as np

# Define the MDP parameters
states = [0, 1, 2]
actions = [0, 1]
P = np.zeros((len(states), len(actions), len(states)))  # Transition probabilities
R = np.zeros((len(states), len(actions), len(states)))  # Rewards
gamma = 0.9  # Discount factor

# Initialize the value function
V = np.zeros(len(states))

# Value iteration algorithm
def value_iteration(states, actions, P, R, gamma, theta=1e-6):
    V = np.zeros(len(states))
    while True:
        delta = 0
        for s in states:
            v = V[s]
            V[s] = max(sum(P[s][a][s_prime] * (R[s][a][s_prime] + gamma * V[s_prime])
                          for s_prime in states) for a in actions)
            delta = max(delta, abs(v - V[s]))
        if delta < theta:
            break
    return V

# Run value iteration
V = value_iteration(states, actions, P, R, gamma)
print("Optimal value function:", V)